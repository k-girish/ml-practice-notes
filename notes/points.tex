\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,bbm}
\usepackage{tikz}
\usepackage{multirow, tabularx}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\E}{\mathop{\mathbb{E}}}

\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\redb}[1]{\textcolor{red}{\textbf{#1}}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\newpara}{\leavevmode\newline}
\newcommand{\hrfullline}{\noindent\makebox[\linewidth]{\rule{\paperwidth}{2pt}}}
\newcommand{\mcaly}{\mathcal{Y}}
\newcommand{\xhat}{\hat{x}}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}

\title{Summary of some important concepts}
\author{Girish Kumar }
\date{Oct 2020}

\begin{document}
\maketitle

\setcounter{secnumdepth}{0}
\tableofcontents

\section{Variational Autoencoder}
\begin{itemize}
    \item Learns a probability distribution for the latent representation vector $z$ that \redb{maximizes the likelihood of given data $x$}, i.e. objective is to maximize 
        $$p(x) = \int p(x|z)p(z)dz$$
    \item It is a feed forward neural network with a \redb{bottleneck layer} in between. This layer acts as the latent space
    \item Neural network input and output is the same value x and can broken down in to \redb{Encoder and Decoder} - hence the name autoencoder
    \item Assume parameters $\theta$ and $\phi$ that parameterize the probability functions $q_\phi(z|x)$ (for encoder) and $p_{\theta}(x|z)$ (for decoder)
    \item We want to maximize the objective function can be shown to be for a particular point $x$
    \begin{align*}
        \mathcal{L}(\theta, \phi) &= \E_{q_\phi(z|x)}{[\log{p_\theta(x|z)}]}  - D_{KL}(q_\phi(z|x)||p_\theta(z)) \\
        &= \frac{1}{L}\sum_{l=1}^L \left( \log {p_\theta(x|z^{(l)})} \right) - D_{KL}(q_\phi(z|x)||p_\theta(z))\\
        \text{where } z^{(l)} \sim q_\phi(z|x)
    \end{align*}
    \item \redb{First term is inversely proportional to the reconstruction loss}, if we assume $p_\theta(x|z) = \mathcal{N}(x;G_\theta(z), \eta I)$, then 
    $$\log{p_\theta(x|z)}=\frac{-1}{2\eta} \Vert x - G_\theta(z) \Vert^2 + \text{ const}$$
    \item \redb{Second term is acting as regularizer}, without this term, $q_\phi(z|x)$ would just be point mass distribution, with mass concentrated on $x$ from the input data. KL divergence forces $q_\phi(z|x)$ to follow a pre-defined distribution $p_theta(z)$ (usually Gaussian).
    \item \blue{Re-parameterization trick}
    \item We can use the latent space to further \redb{sample synthetic data}
        
\end{itemize}

\section{Generative Adversarial Networks (GAN)}

\begin{itemize}
    \item Generative because we are modelling the probability distribution of $p(x)$ or if we have labels $p(x,y)$. This probability distribution can be used to \redb{sample synthetic data}.
    \item Contains two sub-networks - Generator and Discriminator - they both compete in a game trying to defeat each other
    \item \redb{Generator's} goal is to learn how to produce \redb{fake data} that appear real.
    \item \redb{Discriminator's} goal is to identify that images generated by the \redb{generator are fake}. Thus discriminator is simply a \redb{classifier}.
    \item Training a GAN
        \begin{itemize}
            \item \redb{Alternate training} between generator and discriminator, i.e. don't update the weights of discriminator when updating generator and vice versa
            \item During discriminator training, gradient is calculated only on discriminator loss
            \item During generator training, gradient is calculated only on generator loss
            \item After some time,
            \begin{itemize}
                \item \redb{generator becomes more efficient} in producing fake images
                \item \redb{discriminator becomes less accurate} in distinguishing 
                \item generator is not getting an efficient training since the discriminator feedback is less efficient
                \item the training may \redb{not convergence}
            \end{itemize}
        \end{itemize}
    \item Loss function
        \begin{itemize}
            \item In general we need two loss terms, one for each type of sub-network. Some commonly used losses-
            \begin{itemize}
                \item \redb{Minimax Loss}
                    $$\min_G \max_D \left( \E_{x}{[\log {D(x)}]} + \E_{z}{[\log{1-D(G(z))}]} \right)$$
                    Sometimes gets stuck in early stages, prefer Wasserstein Loss
                \item \redb{Modified Minimax Loss}
                    \begin{itemize}
                        \item Generator: maximize $\E_{z}{[\log{D(G(z))}]}$
                        \item Discriminator: same
                        \item Overcomes getting stuck in early stages
                    \end{itemize}
                \item \redb{Wasserstein Loss}
                    $$\min_G \max_D \left( D(x)-D(G(z)) \right)$$
                    Output of $D(x) \in \mathbb{R}$ is not assumed to be a probability, the discriminator aims to produce $D(x)$ as large as possible for real data. Hence the discriminator is more of a critic. \blue{Read more from paper}
                    
            \end{itemize}
        \end{itemize}
    \item Common GAN problems
        \begin{itemize}
            \item \redb{Vanishing gradient} - Discrimnator too good $\implies$ gradient vanishes, generator training is impacted. Solution:
                \begin{itemize}
                    \item Wasserstein Loss
                    \item Modified minimax loss
                \end{itemize}
            \item \redb{Mode Collapse} - If generator is only focusing on a small subset of the original data and discriminator is stuck in some local minima. Solution:
                \begin{itemize}
                    \item Wasserstein Loss
                    \item Unrolled GANs \blue{?}
                \end{itemize}
            \item \redb{Failed to converge} - Usually seen when discriminator is too accurate. Solution:
                \begin{itemize}
                    \item Adding noise to discriminator input
                    \item Regularize discriminator weights
                    \item \blue{read more about above}
                \end{itemize}
        \end{itemize}
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% WAE %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Wasserstein Autoecnoder (WAE)}

\begin{itemize}
    \item \blue{?}
\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Differntial Privacy %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Differntial Privacy}

\begin{itemize}
    \item Some example problems
        \begin{itemize}
            \item Re-identification of an individual example by using an auxiliary data-set to identify key personal information (Netflix challenge and IMDB)
            \item Finding Connections by attacking on an anonymous graph
            \item Identification (or ruling out) of  some characteristics
        \end{itemize}
    \item Some not so good suggestions for privacy
        \begin{itemize}
            \item Only allow large set queries - fails to a differencing attack such as (Query details of a set $\mathbb{S}$ - Query details of a set $\mathbb{S}-\{x\}$)
            \item Add random noise to the result - fails as expectation of repeated queries gives the true result
            \item Detect when answering is unsafe - refusal can be disclosive
            \item Only publish few complete results of individuals who are ok with public data - works but is that what we really want?
        \end{itemize}
    \item \redb{Definition}: M gives $\epsilon$ differential privacy if for all pairs of databases $x, x^\prime$ differing in one row, and all subsets of C of possible outputs,
    $$Pr[M(x) \in C] \leq e^\epsilon Pr[M(x^\prime) \in C]$$
    or equivalently,
    $$ln\left( \frac{Pr[M(x) \in C]}{Pr[M(x^\prime) \in C]} \right) \leq \epsilon$$
    \item \redb{Why this algorithm is better?}
        \begin{itemize}
            \item Is not just focused on re-identification
            \item Is the same even if some Auxiliary information is available
            \item Quantifiable privacy loss (also allows comparison of techniques)
            \item Allows unconditional composition
                $$ln\left( \frac{Pr[M_{1,2}(x) = (r_1, r_2)]}{Pr[M_{1,2}(x^\prime) = (r_1, r_2)]} \right) = ln\left( \frac{Pr[M_1(x) = r_1]Pr[M_2(x) = r_2]}{Pr[M_1(x^\prime) = r_1]Pr[M_2(x^\prime) = r_2]} \right) \leq \epsilon_1+\epsilon_2$$
        \end{itemize}
    \item \redb{Sensitivity of a function}
        $$\Delta f = \max_{x, x^\prime} \Vert f(x)-f(x^\prime) \Vert_1$$
        where $x$ and $x^\prime$ differ only by one row
\end{itemize}

\subsection{Achieve Differential Privacy}

\subsubsection{Laplace Distribution}

\begin{itemize}
    \item About Laplace distribution
        \begin{itemize}
            \item Laplace distribution pdf with mean $\mu$ and variance $2b^2$ is given by
                $$Laplace(\mu,b) = f(x\mid \mu ,b) ={\frac  {1}{2b}}\exp \left(-{\frac  {|x-\mu |}{b}}\right)$$
            \item Tail is fatter than Gaussian and the peak is pointy, key difference is $L_1$ norm instead of $L_2$ norm
        \end{itemize}
    \item To achieve $\epsilon$ differential privacy in the output of a query $f$ of sensitivity $\Delta f$, add noise sampled from the distribution $Lap(\Delta f / \epsilon)$
    \item Example 1
        \begin{itemize}
            \item How many in the database $\dots$ ?
            \item Sensitivity of the query is 1
            \item Sufficient to add noise $\sim Lap(1/\epsilon)$
            \item \blue{Sampling error $\Omega(\sqrt{n})$ ?}
        \end{itemize}
    \item Example 2 - Histogram
        \begin{itemize}
            \item Most popular first name in a given set of names?
            \item Each person maybe present in at-most one bin
            \item Sensitivity of the histogram query is 1
            \item Sufficient to add noise $\sim Lap(1/\epsilon)$
        \end{itemize}
    \item Example 3 - Vector Valued Queries
        \begin{itemize}
            \item Sufficient to add noise $\sim [Lap(\Delta f/\epsilon)]^d$ where $d$ is the dimension of the independent queries
        \end{itemize}
\end{itemize}

\subsubsection{Exponential Mechanism}

\begin{itemize}
    \item \href{https://en.wikipedia.org/wiki/Exponential_mechanism_(differential_privacy)}{Wikipedia link}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{References}
\begin{itemize}
    \item \href{https://developers.google.com/machine-learning/gan}{Google Developer course on GANs}
\end{itemize}

\end{document}
